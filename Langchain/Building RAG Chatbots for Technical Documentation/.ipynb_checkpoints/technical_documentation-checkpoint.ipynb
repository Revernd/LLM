{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2edba47-9e2e-476e-9f2f-fb177b329063",
   "metadata": {},
   "source": [
    "![A car dashboard with lots of new technical features.](images/dashboard.jpg)\n",
    "\n",
    "You're working for a well-known car manufacturer who is looking at implementing LLMs into vehicles to provide guidance to drivers. You've been asked to experiment with integrating car manuals with an LLM to create a context-aware chatbot. They hope that this context-aware LLM can be hooked up to a text-to-speech software to read the model's response aloud.\n",
    "\n",
    "As a proof of concept, you'll integrate several pages from a car manual that contains car warning messages and their meanings and recommended actions. This particular manual, stored as an HTML file, `mg-zs-warning-messages.html`, is from an MG ZS, a compact SUV. Armed with your newfound knowledge of LLMs and LangChain, you'll implement Retrieval Augmented Generation (RAG) to create the context-aware chatbot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2acabac3-1319-441d-81b3-2e1a6f7f36ac",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 50,
    "lastExecutedAt": 1725228098426,
    "lastExecutedByKernel": "34adf0be-ad84-4223-bc99-1dc56d88c335",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Update your environment to Python 3.10 as described above before running this cell\nimport subprocess\nimport pkg_resources\n\ndef install_if_needed(package, version):\n    '''Function to ensure that the libraries used are consistent to avoid errors.'''\n    try:\n        pkg = pkg_resources.get_distribution(package)\n    except pkg_resources.DistributionNotFound:\n        subprocess.check_call([\"pip\", \"install\", f\"{package}=={version}\"])\n\ninstall_if_needed(\"langchain\", \"0.2.2\")\ninstall_if_needed(\"langchain-openai\", \"0.1.8\")\ninstall_if_needed(\"langchain-community\", \"0.2.3\")\ninstall_if_needed(\"unstructured\", \"0.14.4\")\ninstall_if_needed(\"chromadb\", \"0.5.0\")",
    "outputsMetadata": {
     "0": {
      "height": 378,
      "type": "stream"
     },
     "1": {
      "height": 227,
      "type": "stream"
     },
     "2": {
      "height": 80,
      "type": "stream"
     },
     "3": {
      "height": 80,
      "type": "stream"
     },
     "4": {
      "height": 378,
      "type": "stream"
     },
     "5": {
      "height": 378,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'install_if_needed(\"langchain\", \"0.2.2\")\\ninstall_if_needed(\"langchain-openai\", \"0.1.8\")\\ninstall_if_needed(\"langchain-community\", \"0.2.3\")\\ninstall_if_needed(\"langchain-huggingface\", \"1.3.0\")\\ninstall_if_needed(\"unstructured\", \"0.14.4\")\\ninstall_if_needed(\"chromadb\", \"0.5.0\") '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update your environment to Python 3.10 as described above before running this cell\n",
    "''' import subprocess\n",
    "import pkg_resources'''\n",
    "\n",
    "def install_if_needed(package, version):\n",
    "    '''Function to ensure that the libraries used are consistent to avoid errors.'''\n",
    "\n",
    "    pass\n",
    "    '''try:\n",
    "        pkg = pkg_resources.get_distribution(package)\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        subprocess.check_call([\"pip\", \"install\", f\"{package}=={version}\"])'''\n",
    "\n",
    "'''install_if_needed(\"langchain\", \"0.2.2\")\n",
    "install_if_needed(\"langchain-openai\", \"0.1.8\")\n",
    "install_if_needed(\"langchain-community\", \"0.2.3\")\n",
    "install_if_needed(\"langchain-huggingface\", \"1.3.0\")\n",
    "install_if_needed(\"unstructured\", \"0.14.4\")\n",
    "install_if_needed(\"chromadb\", \"0.5.0\") '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61baf413-6464-4c1c-a52d-b3764c124602",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1725228098474,
    "lastExecutedByKernel": "34adf0be-ad84-4223-bc99-1dc56d88c335",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Set your API key to a variable\nimport os\nopenai_api_key = os.environ[\"OPENAI_API_KEY\"]\n\n# Import the required packages\nimport langchain\nfrom langchain import PromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom langchain.document_loaders import UnstructuredHTMLLoader\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import Chroma\nfrom langchain_community.document_loaders import UnstructuredHTMLLoader"
   },
   "outputs": [],
   "source": [
    "# Set your API key to a variable\n",
    "import os\n",
    "#openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Import the required packages\n",
    "import langchain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "#from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bed58c70-1315-409c-a590-a4c7af3cad80",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 53,
    "lastExecutedAt": 1725228098527,
    "lastExecutedByKernel": "34adf0be-ad84-4223-bc99-1dc56d88c335",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Load the HTML as a LangChain document loader\nloader = UnstructuredHTMLLoader(file_path=\"data/mg-zs-warning-messages.html\")\ncar_docs = loader.load()"
   },
   "outputs": [],
   "source": [
    "# Load the HTML as a LangChain document loader\n",
    "loader = UnstructuredHTMLLoader(file_path=\"data/mg-zs-warning-messages.html\")\n",
    "car_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6be93b96-2807-4bdc-980f-3e72e661cecd",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 46,
    "lastExecutedAt": 1725228098574,
    "lastExecutedByKernel": "34adf0be-ad84-4223-bc99-1dc56d88c335",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Define variables\nchunk_size = 300\nchunk_overlap = 100\n\n# Split the HTML\nsplitter = RecursiveCharacterTextSplitter(\n    chunk_size=chunk_size,\n    chunk_overlap=chunk_overlap,\n    separators=['\\n\\n', '\\n',' '])"
   },
   "outputs": [],
   "source": [
    "# Define variables\n",
    "chunk_size = 300\n",
    "chunk_overlap = 100\n",
    "\n",
    "# Split the HTML\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=['\\n\\n', '\\n',' '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6d903ea-d0b0-49f9-9166-0233aa871f3a",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1725228098626,
    "lastExecutedByKernel": "34adf0be-ad84-4223-bc99-1dc56d88c335",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "docs = splitter.split_documents(car_docs)\ndocs[:2]"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/mg-zs-warning-messages.html'}, page_content='Warning Message Procedure Cruise Control Fault Indicates that the cruise control system has detected a fault. Please consult an MG Authorised Repairer as soon as possible. Active Speed Limiter Fault Indicates that the active speed limit system has detected a fault. Contact an MG Authorised Repairer'),\n",
       " Document(metadata={'source': 'data/mg-zs-warning-messages.html'}, page_content='that the active speed limit system has detected a fault. Contact an MG Authorised Repairer as soon as possible. Engine Coolant Temperature High High engine coolant temperature could result in severe damage. As soon as conditions permit, safely stop the vehicle and switch off the engine and contact')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = splitter.split_documents(car_docs)\n",
    "docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfdbf0df-7a20-4b4f-a2b0-76044d40aad5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 297,
    "lastExecutedAt": 1725228098924,
    "lastExecutedByKernel": "34adf0be-ad84-4223-bc99-1dc56d88c335",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from langchain_huggingface import HuggingFaceEndpointEmbeddings\nvectorstore = Chroma.from_documents(\n    docs,\n    embedding=HuggingFaceEndpointEmbeddings(\n    model=\"sentence-transformers/all-mpnet-base-v2\",\n    task=\"feature-extraction\",\n    huggingfacehub_api_token='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',\n) ,\n    persist_directory=os.getcwd()\n)"
   },
   "outputs": [],
   "source": [
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs,\n",
    "    embedding=HuggingFaceEndpointEmbeddings(\n",
    "    model=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    task=\"feature-extraction\",\n",
    "    huggingfacehub_api_token='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',\n",
    ") ,\n",
    "    persist_directory=os.getcwd()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "937a352f-7311-40df-9990-9161d7d379bf",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1725228101798,
    "lastExecutedByKernel": "34adf0be-ad84-4223-bc99-1dc56d88c335",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Configure the vector store as a retriever\nretriever = vectorstore.as_retriever(\n    search_type=\"similarity\",\n    search_kwargs={\"k\":3}\n)"
   },
   "outputs": [],
   "source": [
    "# Configure the vector store as a retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39d4a5a7-890d-4d9f-9ea4-570d4d7a89d8",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1725228101846,
    "lastExecutedByKernel": "34adf0be-ad84-4223-bc99-1dc56d88c335",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from langchain.prompts import ChatPromptTemplate\n# Add placeholders to the message string\nmessage = \"\"\"\nAnswer the following question using the context provided:\n\nContext:\n{context}\n\nQuestion:\n{question}\n\nAnswer:\n\"\"\"\n\n# Create a chat prompt template from the message string\nprompt_template = ChatPromptTemplate.from_messages([(\"human\", message)])"
   },
   "outputs": [],
   "source": [
    "# Add placeholders to the message string\n",
    "message = \"\"\"\n",
    "Answer the following question using the context provided:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Create a chat prompt template from the message string\n",
    "prompt_template = ChatPromptTemplate.from_messages([(\"human\", message)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "549208b0-f95b-4fb7-8cc9-68e85dd27c11",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1725228101895,
    "lastExecutedByKernel": "34adf0be-ad84-4223-bc99-1dc56d88c335",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Create a chain to link retriever, prompt_template, and llm\nfrom langchain_huggingface import HuggingFaceEndpoint\n\nllm = HuggingFaceEndpoint(repo_id='tiiuae/falcon-7b-instruct', huggingfacehub_api_token='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')\n\nrag_chain = ({\"context\": retriever, \"question\": RunnablePassthrough()}\n            | prompt_template\n            | llm)\n",
    "outputsMetadata": {
     "0": {
      "height": 143,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\ruthv\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Create a chain to link retriever, prompt_template, and llm\n",
    "llm = HuggingFaceEndpoint(repo_id='tiiuae/falcon-7b-instruct', huggingfacehub_api_token='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')\n",
    "\n",
    "rag_chain = ({\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "            | prompt_template\n",
    "            | llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb5c1058-3880-4477-ae48-d4023c8d0cf7",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 2147,
    "lastExecutedAt": 1725228104042,
    "lastExecutedByKernel": "34adf0be-ad84-4223-bc99-1dc56d88c335",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "answer = rag_chain.invoke(\"The Gasoline Particular Filter Full warning has appeared. What does this mean and what should I do about it?\")\nprint(answer)",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gasoline Particular Filter Full warning indicates that the gasoline particulate filter, which helps to clean the air entering the engine, has reached its maximum capacity and needs to be replaced. It is important to replace this filter as soon as possible to prevent any further engine damage and improve fuel efficiency.\n"
     ]
    }
   ],
   "source": [
    "answer = rag_chain.invoke(\"The Gasoline Particular Filter Full warning has appeared. What does this mean and what should I do about it?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89cb6c1-17a8-4fff-af9f-0f9e60b128cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
